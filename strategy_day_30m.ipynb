{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import temp.file as temp_files\n",
    "%config IPCompleter.greedy=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_names = ['date', 'time', 'open', 'high', 'low', 'close', 'volume']\n",
    "data = pd.read_csv(temp_files.get('EURUSD30.csv'), skiprows=1,\n",
    "                      header=None, names=features_names, index_col=[0], parse_dates=[[0,1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def getDayBarSets(day_df, count_decimal=5):\n",
    "    \"\"\"\n",
    "    return entry points (-1)\n",
    "    \"\"\"\n",
    "    \n",
    "    # check\n",
    "    if len(day_df) == 0:\n",
    "        return []\n",
    "    \n",
    "    # prices settings\n",
    "    pips_multiplier = 10 ** count_decimal\n",
    "    need_bars = 5\n",
    "    pips_to_line_max = 25\n",
    "    pips_min_delta = 250\n",
    "    day_open_price = day_df.iloc[0].open\n",
    "    \n",
    "    # frame settings\n",
    "    from_bar_id = 0\n",
    "    step = 1\n",
    "    frame_length = 12\n",
    "    \n",
    "    return_data = [ ]\n",
    "\n",
    "    while True:\n",
    "        \n",
    "        # frame - 6h\n",
    "        frame = day_df[from_bar_id:from_bar_id+frame_length]\n",
    "        from_bar_id+=1\n",
    "        if len(frame) == 0 or len(frame) < frame_length:\n",
    "            break\n",
    "        \n",
    "        # check delta\n",
    "        max_price = frame['high'].max()\n",
    "        low_price = frame['low'].min()\n",
    "        pips_delta_calc = (max_price - low_price) * pips_multiplier\n",
    "        \n",
    "        # check min delta\n",
    "        if pips_delta_calc < pips_min_delta:\n",
    "            continue\n",
    "            \n",
    "        # find pips ti line    \n",
    "        before_close = frame[\"close\"][-2]\n",
    "        pips_to_line = abs(before_close - day_open_price) * pips_multiplier\n",
    "        \n",
    "        # check pips to line\n",
    "        if pips_to_line > pips_to_line_max:\n",
    "            continue\n",
    "        \n",
    "        return_data.append({\n",
    "            \"day_open_price\":day_open_price,\n",
    "            \"frame\":frame,\n",
    "            \"pips_to_line\":pips_to_line\n",
    "        })\n",
    "        continue\n",
    "        \n",
    "    return return_data  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "bar_sets = []\n",
    "for j in pd.date_range('2014-01-01', periods=1500):\n",
    "    result = getDayBarSets(data.loc[data.index.date == j.date()])\n",
    "    if result:\n",
    "        for one in result:\n",
    "            bar_sets.append(one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_learn_data(bars_info):\n",
    "    \"\"\"\n",
    "    return data sets for machine learning\n",
    "    \"\"\"\n",
    "    day_open_price = bars_info[\"day_open_price\"]\n",
    "    frame = bars_info[\"frame\"]\n",
    "    target_bar = frame.iloc[-1]\n",
    "    bars_before_target = frame[:-1]\n",
    "    pips_to_line = bars_info[\"pips_to_line\"]\n",
    "    \n",
    "    # middle before target\n",
    "    middle_before_target_set = []\n",
    "    middle_before_target_set.append(bars_before_target[\"open\"].mean())\n",
    "    middle_before_target_set.append(bars_before_target[\"high\"].mean())\n",
    "    middle_before_target_set.append(bars_before_target[\"low\"].mean())\n",
    "    middle_before_target_set.append(bars_before_target[\"close\"].mean())\n",
    "    # ---\n",
    "    middle_before_target_frame_set = normalize_values(middle_before_target_set)\n",
    "    \n",
    "    # middle 4 last bars\n",
    "    last_four = bars_before_target[-4:]\n",
    "    middle_last_four_set = []\n",
    "    middle_last_four_set.append(last_four[\"open\"].mean())\n",
    "    middle_last_four_set.append(last_four[\"high\"].mean())\n",
    "    middle_last_four_set.append(last_four[\"low\"].mean())\n",
    "    middle_last_four_set.append(last_four[\"close\"].mean())\n",
    "    # ---\n",
    "    middle_last_four_set = normalize_values(middle_last_four_set)\n",
    "    \n",
    "    # last four binaries\n",
    "    binary_set = []\n",
    "    \n",
    "    for index, bar in last_four.iterrows():\n",
    "        # open info\n",
    "        binary_set.append(1 if bar[\"open\"] > day_open_price else -1)\n",
    "        # high info\n",
    "        binary_set.append(1 if bar[\"high\"] > day_open_price else -1)\n",
    "        # low info\n",
    "        binary_set.append(1 if bar[\"low\"] > day_open_price else -1)\n",
    "        # close info\n",
    "        binary_set.append(1 if bar[\"close\"] > day_open_price else -1)\n",
    "        # type info\n",
    "        binary_set.append(1 if bar[\"open\"] < bar[\"close\"] else -1)   \n",
    "    \n",
    "    # target\n",
    "    target = 1 if target_bar[\"open\"] < target_bar[\"close\"] else -1\n",
    "    \n",
    "    data_set = middle_before_target_frame_set + middle_last_four_set + binary_set\n",
    "    \n",
    "    return data_set, target\n",
    "\n",
    "def normalize_values(list_prices):\n",
    "    normalize_data = []\n",
    "    max_value = max(list_prices)\n",
    "    min_value = min(list_prices)\n",
    "    for val in list_prices:\n",
    "        normal = normalize_value(min_value, max_value, val)\n",
    "        normalize_data.append(normal)\n",
    "    return normalize_data\n",
    "\n",
    "def normalize_value(min_value, max_value, target_value):\n",
    "    return (target_value - (max_value + min_value) / 2) / ((max_value - min_value) / 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sets = []\n",
    "targets = []\n",
    "\n",
    "for bars_info in bar_sets:\n",
    "    data_set, target = create_learn_data(bars_info)\n",
    "    data_sets.append(data_set)\n",
    "    targets.append(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data sets count 1471\n"
     ]
    }
   ],
   "source": [
    "print(\"Data sets count \" + str(len(data_sets)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_buy = []\n",
    "data_sell = []\n",
    "\n",
    "for data_set, target in zip(data_sets, targets):\n",
    "    if target == 1:\n",
    "        data_buy.append(data_set)\n",
    "    else:\n",
    "        data_sell.append(data_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = \\\n",
    "            train_test_split(data_sets, targets, shuffle=False, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Форма исходного массива: (1103, 28)\n",
      "Форма массива после сокращения размерности: (1103, 5)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# оставляем главные компоненты (уменьшение размерности)\n",
    "pca = PCA(n_components=5)\n",
    "# подгоняем модель PCA на наборе данных\n",
    "pca.fit(X_train_scaled)\n",
    "# преобразуем данные к первым двум главным компонентам\n",
    "X_train_pca = pca.transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)\n",
    "print(\"Форма исходного массива: {}\".format(str(np.array(X_train).shape)))\n",
    "print(\"Форма массива после сокращения размерности: {}\".format(str(X_train_pca.shape)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=None, n_neighbors=100, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "model = KNeighborsClassifier(n_neighbors=100)\n",
    "    \n",
    "#model = GradientBoostingClassifier(random_state=0, learning_rate=0.001, max_depth=3)\n",
    "\n",
    "#model = MLPClassifier(solver='lbfgs', random_state=0, hidden_layer_sizes=[100, 20, 5])\n",
    "\n",
    "model.fit(X_train_pca, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Правильность на обучающем наборе: 0.536\n",
      "Правильность на тестовом наборе: 0.549\n"
     ]
    }
   ],
   "source": [
    "print(\"Правильность на обучающем наборе: {:.3f}\".format(model.score(X_train_pca, y_train)))\n",
    "print(\"Правильность на тестовом наборе: {:.3f}\". format(model.score(X_test_pca, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (coins)",
   "language": "python",
   "name": "coins"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
